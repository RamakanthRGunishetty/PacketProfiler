{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WmapR1szTNEE",
        "outputId": "232de738-3761-45d2-ec99-75617d34e9ad"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
          ]
        }
      ],
      "source": [
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend as K\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "\n",
        "# Load the data\n",
        "try:\n",
        "    names = ['protocol','src_ip' , 'src_port', 'dst_ip', 'dst_port', 'ndpi_proto_num', 'src2dst_packets',\n",
        "            'src2dst_bytes', 'dst2src_packets', 'dst2src_bytes', 'ndpi_proto', 'class']\n",
        "    df = pd.read_csv('/content/processed_data.csv')\n",
        "    array = df.values\n",
        "\n",
        "    X = np.asarray(df[['protocol', 'src_port', 'dst_port', 'src2dst_packets', 'src2dst_bytes', 'dst2src_packets','dst2src_bytes']][1:])\n",
        "    y = []\n",
        "\n",
        "    my_tags = []\n",
        "    classes = open(\"dnn.txt\", \"w+\")\n",
        "    for i in df['class'][1:]:\n",
        "        if i not in my_tags:\n",
        "            my_tags.append(i)\n",
        "    for i in df['class'][1:]:\n",
        "        classes.write(i+\" \"+str(my_tags.index(i))+\"\\n\")\n",
        "        y.append(my_tags.index(i))\n",
        "    y = np.asarray(y)\n",
        "    print(X.shape, y.shape)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading or processing data: {e}\")\n",
        "\n",
        "# Split the data\n",
        "try:\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=True)\n",
        "    features = len(x_train[0])\n",
        "except Exception as e:\n",
        "    print(f\"Error splitting data: {e}\")\n",
        "\n",
        "# Define the model\n",
        "try:\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(features, kernel_regularizer=tf.keras.regularizers.l1(0.1)),\n",
        "        keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.1)),\n",
        "        keras.layers.Dense(256, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l1(0.1)),\n",
        "        keras.layers.Dense(128, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.1)),\n",
        "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['acc', f1_m, precision_m, recall_m])\n",
        "except Exception as e:\n",
        "    print(f\"Error defining or compiling the model: {e}\")\n",
        "\n",
        "# Train the model\n",
        "try:\n",
        "    history = model.fit(x_train, y_train, batch_size=1000, epochs=400)\n",
        "    loss, accuracy, f1_score, precision, recall = model.evaluate(x_test, np.array(y_test), verbose=0)\n",
        "except Exception as e:\n",
        "    print(f\"Error training the model: {e}\")\n",
        "\n",
        "# Save the model\n",
        "try:\n",
        "    model.save(\"dnn_model.h5\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the model: {e}\")\n",
        "\n",
        "# Load the model (for example)\n",
        "# try:\n",
        "#     model = keras.models.load_model('dnn_model.h5', custom_objects={'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
        "# except Exception as e:\n",
        "#     print(f\"Error loading the model: {e}\")\n",
        "\n",
        "try:\n",
        "    y_predict = model.predict(x_test)\n",
        "\n",
        "    for i in y_predict:\n",
        "        print(np.argmax(i))\n",
        "    print(f'loss: {loss}, acc: {accuracy}, f1_score: {f1_score}, precision: {precision}, recall: {recall}')\n",
        "    print(model.summary())\n",
        "    print(x_test[0])\n",
        "except Exception as e:\n",
        "    print(f\"Error predicting or printing results: {e}\")\n",
        "\n",
        "# Plot the training accuracy\n",
        "try:\n",
        "    pyplot.subplot(212)\n",
        "    pyplot.title('Accuracy')\n",
        "    pyplot.plot(history.history['acc'], label='train')\n",
        "    pyplot.legend()\n",
        "    pyplot.show()\n",
        "except Exception as e:\n",
        "    print(f\"Error plotting training accuracy: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCOhv_JZTNEH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
